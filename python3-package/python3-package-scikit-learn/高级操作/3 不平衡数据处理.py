from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
from imblearn.pipeline import make_pipeline as make_imb_pipeline
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_classification
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns


def load_data(random_state=42):
    """
    ç”Ÿæˆæ¨¡æ‹Ÿçš„ä¸å¹³è¡¡äºŒåˆ†ç±»æ•°æ®é›†

    è¿”å›:
        X (np.ndarray): ç‰¹å¾çŸ©é˜µ
        y (np.ndarray): æ ‡ç­¾å‘é‡
    """
    # è®¾ç½®ç±»åˆ«æ¯”ä¾‹ä¸º 9:1 çš„ä¸å¹³è¡¡æ•°æ®
    X, y = make_classification(
        n_samples=1000,
        n_features=20,
        n_informative=10,
        n_redundant=2,
        n_classes=2,
        weights=[0.9, 0.1],
        random_state=random_state
    )
    return X, y


def split_data(X, y, test_size=0.2, random_state=42):
    """
    åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†

    å‚æ•°:
        X (np.ndarray): ç‰¹å¾æ•°æ®
        y (np.ndarray): æ ‡ç­¾æ•°æ®
        test_size (float): æµ‹è¯•é›†æ¯”ä¾‹
        random_state (int): éšæœºç§å­

    è¿”å›:
        X_train, X_test, y_train, y_test: å››ç»„åˆ’åˆ†ç»“æœ
    """
    return train_test_split(X, y, test_size=test_size, random_state=random_state)


def build_smote_pipeline():
    """
    æ„å»ºä»…ä½¿ç”¨ SMOTE çš„ç®¡é“

    è¿”å›:
        pipeline (Pipeline): åŒ…å«æ ‡å‡†åŒ–ã€SMOTE å’Œåˆ†ç±»å™¨çš„ç®¡é“
    """
    pipeline = make_imb_pipeline(
        StandardScaler(),
        SMOTE(sampling_strategy='minority', random_state=42),
        RandomForestClassifier(random_state=42)
    )
    return pipeline


def build_combined_pipeline():
    """
    æ„å»ºç»„åˆé‡‡æ ·æ–¹æ³•çš„ç®¡é“ï¼šSMOTE + éšæœºæ¬ é‡‡æ ·

    è¿”å›:
        pipeline (Pipeline): åŒ…å«æ ‡å‡†åŒ–ã€SMOTEã€éšæœºæ¬ é‡‡æ ·å’Œåˆ†ç±»å™¨çš„ç®¡é“
    """
    pipeline = make_imb_pipeline(
        StandardScaler(),
        SMOTE(sampling_strategy=0.5, random_state=42),     # å°†å°‘æ•°ç±»ä¸Šé‡‡æ ·è‡³ 50%
        RandomUnderSampler(sampling_strategy=0.8, random_state=42),  # å¤šæ•°ç±»ä¸‹é‡‡æ ·è‡³ 80%
        RandomForestClassifier(random_state=42)
    )
    return pipeline


def evaluate_model(pipeline, X_train, y_train, X_test, y_test, name="æ¨¡å‹"):
    """
    è®­ç»ƒå¹¶è¯„ä¼°æ¨¡å‹ï¼Œè¾“å‡ºåˆ†ç±»æŠ¥å‘Šä¸æ··æ·†çŸ©é˜µ

    å‚æ•°:
        pipeline (Pipeline): æ¨¡å‹ç®¡é“
        X_train (np.ndarray): è®­ç»ƒç‰¹å¾
        y_train (np.ndarray): è®­ç»ƒæ ‡ç­¾
        X_test (np.ndarray): æµ‹è¯•ç‰¹å¾
        y_test (np.ndarray): æµ‹è¯•æ ‡ç­¾
        name (str): æ¨¡å‹åç§°ï¼ˆç”¨äºæ‰“å°ï¼‰

    è¿”å›:
        report (str): åˆ†ç±»æŠ¥å‘Šå­—ç¬¦ä¸²
    """
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒï¼š{name}")

    pipeline.fit(X_train, y_train)
    y_pred = pipeline.predict(X_test)

    print("âœ… åˆ†ç±»æŠ¥å‘Š:")
    report = classification_report(y_test, y_pred, target_names=['ç±»åˆ« 0', 'ç±»åˆ« 1'])
    print(report)

    # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.xlabel('é¢„æµ‹å€¼')
    plt.ylabel('çœŸå®å€¼')
    plt.title(f"{name} æ··æ·†çŸ©é˜µ")
    plt.savefig(f"confusion_matrix_{name}.png", dpi=150)
    plt.close()

    return report


def plot_class_distribution(y, title="ç±»åˆ«åˆ†å¸ƒ"):
    """
    å¯è§†åŒ–æ•°æ®é›†ä¸­å„ç±»åˆ«æ ·æœ¬æ•°é‡

    å‚æ•°:
        y (np.ndarray): æ ‡ç­¾æ•°ç»„
        title (str): å›¾è¡¨æ ‡é¢˜
    """
    class_counts = np.bincount(y)
    plt.figure(figsize=(6, 4))
    sns.barplot(x=np.arange(len(class_counts)), y=class_counts, palette="viridis")
    plt.xticks(np.arange(len(class_counts)), [f'ç±»åˆ« {i}' for i in range(len(class_counts))])
    plt.xlabel("ç±»åˆ«")
    plt.ylabel("æ ·æœ¬æ•°")
    plt.title(title)
    plt.grid(axis='y', alpha=0.3)
    plt.savefig(f"class_distribution_{title}.png", dpi=150)
    plt.close()


def main():
    # 1. åŠ è½½æ•°æ®
    X, y = load_data()
    print("ğŸ“Š åŸå§‹æ•°æ®ç±»åˆ«åˆ†å¸ƒ:", dict(zip(*np.unique(y, return_counts=True)))
    plot_class_distribution(y, "åŸå§‹æ•°æ®")

    # 2. æ•°æ®åˆ’åˆ†
    X_train, X_test, y_train, y_test = split_data(X, y)

    # 3. æ„å»ºå¹¶è¯„ä¼° SMOTE ç®¡é“
    smote_pipeline = build_smote_pipeline()
    evaluate_model(smote_pipeline, X_train, y_train, X_test, y_test, name="SMOTE")

    # 4. æ„å»ºå¹¶è¯„ä¼°ç»„åˆé‡‡æ ·ç®¡é“
    combined_pipeline = build_combined_pipeline()
    evaluate_model(combined_pipeline, X_train, y_train, X_test, y_test, name="SMOTE+æ¬ é‡‡æ ·")


if __name__ == "__main__":
    main()
